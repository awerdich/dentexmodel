{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebc52caa-e5ff-42ad-9bb6-84891f453249",
   "metadata": {},
   "source": [
    "## Notebook 6: The Lightning Model Class ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "146bbe69-a3c4-430d-a5f8-74fa54188d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project module version: 0.0.post1.dev25+ga99b50c.d20231228\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "# Matplotlib for plotting\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "\n",
    "# PyTorch methods\n",
    "from torch.utils.data import DataLoader\n",
    "import torchxrayvision as xrv\n",
    "import torch.nn as nn\n",
    "\n",
    "# Albumentations library\n",
    "import albumentations as alb\n",
    "\n",
    "# Appearance of the Notebook\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "np.set_printoptions(linewidth=110)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Import this module with autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import dentexmodel as dm\n",
    "from dentexmodel.imageproc import ImageData\n",
    "from dentexmodel.torchdataset import DatasetFromDF, load_and_process_image\n",
    "\n",
    "print(f'Project module version: {dm.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb742ac6-b8be-4342-97cc-b91acf1e3805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path settings \n",
    "dentex_dir = os.path.join(os.environ['HOME'], 'data', 'dentex')\n",
    "data_dir = os.path.join(dentex_dir, 'dentex_disease')\n",
    "image_dir = os.path.join(data_dir, 'quadrant-enumeration-disease', 'xrays', 'crop')\n",
    "data_file_name = 'dentex_disease_datasplit.parquet'\n",
    "data_file = os.path.join(dentex_dir, data_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7358557-53d8-4d69-b694-55c406c0f47f",
   "metadata": {},
   "source": [
    "### Create PyTorch datasets from data frame ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64692d68-33f9-4a65-a937-6fa485594f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Caries               0\n",
       "Deep Caries          1\n",
       "Impacted             2\n",
       "Periapical Lesion    3\n",
       "Name: 0, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df = pd.read_parquet(data_file)\n",
    "# Convert class names to labels\n",
    "cl_names = sorted(list(data_df['label'].unique()))\n",
    "# Let's assign number to the classes\n",
    "label_dict = dict(zip(cl_names, range(len(cl_names))))\n",
    "cl_dict = dict(zip(label_dict.values(), label_dict.keys()))\n",
    "\n",
    "# Add the class labels to the data frame\n",
    "seed = np.random.seed(123)\n",
    "data_df = data_df.\\\n",
    "                assign(cl=data_df['label'].apply(lambda l: label_dict.get(l))).\\\n",
    "                sample(frac=1, random_state=seed).\\\n",
    "                reset_index(drop=True)\n",
    "\n",
    "# Show the class labels\n",
    "display(pd.DataFrame(label_dict, index=[0]).iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0af688f-9c27-4227-8374-06643a7c49a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Select the training samples from our data frame\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_df \u001b[38;5;241m=\u001b[39m \u001b[43mdata_df\u001b[49m\u001b[38;5;241m.\u001b[39mloc[data_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m val_df \u001b[38;5;241m=\u001b[39m data_df\u001b[38;5;241m.\u001b[39mloc[data_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m test_df \u001b[38;5;241m=\u001b[39m data_df\u001b[38;5;241m.\u001b[39mloc[data_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Select the training samples from our data frame\n",
    "train_df = data_df.loc[data_df['dataset']=='train']\n",
    "val_df = data_df.loc[data_df['dataset']=='val']\n",
    "test_df = data_df.loc[data_df['dataset']=='test']\n",
    "\n",
    "train_samples = sorted(list(train_df['box_name'].unique()))\n",
    "print(f'Found {len(train_samples)} samples in the training set.')\n",
    "val_samples = sorted(list(val_df['box_name'].unique()))\n",
    "print(f'Found {len(val_samples)} samples in the validation set.')\n",
    "test_samples = sorted(list(test_df['box_name'].unique()))\n",
    "print(f'Found {len(test_samples)} samples in the test set.')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b366254d-a33b-4779-855a-48242cf1f6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentations\n",
    "# Image augmentations is part of the PyTorch dataset\n",
    "\n",
    "# The output of this transformation must match the required input size for the model\n",
    "max_image_size = 550\n",
    "im_size = 512\n",
    "\n",
    "# Definition of the image augmentations for the training set\n",
    "train_transform = alb.Compose([\n",
    "    alb.Resize(im_size + 32, im_size + 32),\n",
    "    alb.RandomCrop(im_size, im_size),\n",
    "    alb.HorizontalFlip(),\n",
    "    alb.ShiftScaleRotate(),\n",
    "    alb.Blur(),\n",
    "    alb.RandomGamma(),\n",
    "    alb.Sharpen(),\n",
    "    alb.GaussNoise(),\n",
    "    alb.CoarseDropout(16, 32, 32),\n",
    "    alb.CLAHE(),\n",
    "    alb.Normalize(mean=0, std=1)])\n",
    "\n",
    "# Vor validation and testing, we do not want any augmentations\n",
    "# but we will still need the correct input size and image normalization\n",
    "val_transform = alb.Compose([\n",
    "    alb.Resize(im_size, im_size),\n",
    "    alb.Normalize(mean=0, std=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5edc6ffb-c54a-41ab-b899-20190b777ea8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DatasetFromDF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create the data sets from the data frame\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDatasetFromDF\u001b[49m(data\u001b[38;5;241m=\u001b[39mtrain_df,\n\u001b[1;32m      3\u001b[0m                               file_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbox_file\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m                               label_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcl\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m                               max_image_size\u001b[38;5;241m=\u001b[39mmax_image_size,\n\u001b[1;32m      6\u001b[0m                               transform\u001b[38;5;241m=\u001b[39mtrain_transform,\n\u001b[1;32m      7\u001b[0m                               validate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m DatasetFromDF(data\u001b[38;5;241m=\u001b[39mval_df,\n\u001b[1;32m     10\u001b[0m                             file_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbox_file\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m                             label_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcl\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m                             max_image_size\u001b[38;5;241m=\u001b[39mmax_image_size,\n\u001b[1;32m     13\u001b[0m                             transform\u001b[38;5;241m=\u001b[39mval_transform,\n\u001b[1;32m     14\u001b[0m                             validate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m DatasetFromDF(data\u001b[38;5;241m=\u001b[39mtest_df,\n\u001b[1;32m     17\u001b[0m                              file_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbox_file\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     18\u001b[0m                              label_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcl\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     19\u001b[0m                              max_image_size\u001b[38;5;241m=\u001b[39mmax_image_size,\n\u001b[1;32m     20\u001b[0m                              transform\u001b[38;5;241m=\u001b[39mval_transform,\n\u001b[1;32m     21\u001b[0m                              validate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DatasetFromDF' is not defined"
     ]
    }
   ],
   "source": [
    "# Create the data sets from the data frame\n",
    "train_dataset = DatasetFromDF(data=train_df,\n",
    "                              file_col='box_file',\n",
    "                              label_col='cl',\n",
    "                              max_image_size=max_image_size,\n",
    "                              transform=train_transform,\n",
    "                              validate=True)\n",
    "\n",
    "val_dataset = DatasetFromDF(data=val_df,\n",
    "                            file_col='box_file',\n",
    "                            label_col='cl',\n",
    "                            max_image_size=max_image_size,\n",
    "                            transform=val_transform,\n",
    "                            validate=True)\n",
    "\n",
    "test_dataset = DatasetFromDF(data=test_df,\n",
    "                             file_col='box_file',\n",
    "                             label_col='cl',\n",
    "                             max_image_size=max_image_size,\n",
    "                             transform=val_transform,\n",
    "                             validate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2bc348-585b-4b12-a0ca-5c419ce4fb87",
   "metadata": {},
   "source": [
    "### The lightning model ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d9b3e30-cc88-46e2-ba82-49112c2321fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdentexmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtoothmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ToothModel\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m ToothModel(train_dataset\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_dataset\u001b[49m,\n\u001b[1;32m      3\u001b[0m                    val_dataset\u001b[38;5;241m=\u001b[39mval_dataset,\n\u001b[1;32m      4\u001b[0m                    test_dataset\u001b[38;5;241m=\u001b[39mtest_dataset,\n\u001b[1;32m      5\u001b[0m                    batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[1;32m      6\u001b[0m                    num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from dentexmodel.models.toothmodel import ToothModel\n",
    "model = ToothModel(train_dataset=train_dataset,\n",
    "                   val_dataset=val_dataset,\n",
    "                   test_dataset=test_dataset,\n",
    "                   batch_size=4,\n",
    "                   num_workers=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
